\documentclass[12pt,a4paper]{article}

% ============================================================
% Packages
% ============================================================
\usepackage[margin=2.5cm]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[hidelinks]{hyperref}
\usepackage{enumitem}

% Compact spacing
\setlength{\parskip}{0.4em}
\setlength{\parindent}{0em}

% ============================================================
% Title
% ============================================================
\title{%
  \textbf{Hierarchical $k$-GNN Explanations via\\Generative Interpretation Networks}\\
  \large Comparing 1-GNN and 1-2-GNN for Model-Level\\Graph Classification Interpretability
}
\author{[Author Name]}
\date{February 2026}

\begin{document}
\maketitle

% ============================================================
% Abstract
% ============================================================
\begin{abstract}
Graph Neural Networks (GNNs) are powerful tools for graph classification, yet their decision processes remain opaque. Higher-order $k$-GNNs, which operate on $k$-element subsets of nodes, provably increase expressive power beyond the Weisfeiler--Leman hierarchy, but it is unclear whether this additional expressiveness translates into more interpretable explanations. We investigate this question by comparing a standard 1-GNN with a hierarchical 1-2-GNN using the GIN-Graph framework for model-level explanation generation. Our pipeline trains $k$-GNN classifiers on the MUTAG and PROTEINS benchmarks, then uses a Wasserstein GAN with gradient penalty to generate class-representative explanation graphs guided by the pretrained classifier. We introduce a fully differentiable dense wrapper that maintains gradient flow through both node features and adjacency matrices for hierarchical models. On MUTAG, both models achieve identical classification accuracy (89.5\%), yet the 1-2-GNN produces explanations with substantially higher validity rates (92\% vs.\ 82\%), validation scores (0.80 vs.\ 0.71), and degree realism (0.621 vs.\ 0.504), demonstrating that higher-order expressiveness improves explanation quality independently of classification performance. On PROTEINS, the 1-GNN outperforms in both classification (77.6\% vs.\ 68.6\%) and explanation quality, with the 1-2-GNN's predictions collapsing to near-constant outputs. These results suggest that the benefit of higher-order message passing for interpretability is dataset-dependent and fundamentally bounded by classifier quality.
\end{abstract}

\newpage
\tableofcontents
\newpage

% ============================================================
% 1. Introduction
% ============================================================
\section{Introduction}
\label{sec:introduction}

Graph Neural Networks (GNNs) have become the standard approach for learning on graph-structured data, achieving strong results on tasks ranging from molecular property prediction to social network analysis. Despite their effectiveness, GNNs suffer from the same interpretability challenges as other deep learning models: their predictions are difficult to explain in human-understandable terms.

The expressiveness of standard message-passing GNNs is bounded by the 1-dimensional Weisfeiler--Leman (1-WL) graph isomorphism test~\cite{morris2019weisfeiler}. Morris et al.~\cite{morris2019weisfeiler} proposed $k$-GNNs that operate on $k$-element subsets of nodes, achieving expressiveness equivalent to the $k$-WL test. In theory, higher-order $k$-GNNs can distinguish graph structures that standard GNNs cannot.

A natural question arises: \emph{does this additional structural expressiveness translate into better model-level explanations?} If a model captures richer structural patterns, the explanations it produces---representative graphs that characterise each class---should be more informative and structurally valid.

We investigate this question using the GIN-Graph framework~\cite{sun2025gingraph}, which generates model-level explanation graphs through a GAN-based approach guided by a pretrained classifier. Model-level explanations aim to answer the question ``what does a typical graph of class $c$ look like according to the model?'' by generating new graphs that maximise the model's confidence for that class while remaining structurally realistic. This contrasts with instance-level methods that explain individual predictions by identifying important subgraphs.

Specifically, we compare:
\begin{itemize}[nosep]
  \item A \textbf{1-GNN}: standard node-level message passing, equivalent to 1-WL;
  \item A \textbf{1-2-GNN}: hierarchical architecture combining node-level (1-GNN) and pairwise (2-GNN) message passing, achieving expressiveness beyond 1-WL.
\end{itemize}

Our contributions are:
\begin{enumerate}[nosep]
  \item A fully differentiable dense wrapper enabling GIN-Graph training with hierarchical $k$-GNN classifiers, maintaining gradient flow through adjacency matrices at both the 1-GNN and 2-GNN levels.
  \item A corrected validation metric that computes actual cosine similarity between generated and real graph embeddings, replacing the original proxy of using prediction probability.
  \item An empirical comparison of explanation quality across two benchmark datasets (MUTAG, PROTEINS), showing that the benefit of higher-order message passing for interpretability is dataset-dependent.
\end{enumerate}

% ============================================================
% 2. Background
% ============================================================
\section{Background}
\label{sec:background}

\subsection{Graph Neural Networks}

A graph $G = (V, E)$ consists of a node set $V$ with $|V| = n$ and an edge set $E \subseteq V \times V$. Each node $v \in V$ carries a feature vector $\mathbf{x}_v \in \mathbb{R}^d$. We denote the adjacency matrix as $\mathbf{A} \in \{0,1\}^{n \times n}$ where $A_{uv} = 1$ if $(u,v) \in E$, and the feature matrix as $\mathbf{X} \in \mathbb{R}^{n \times d}$ where row $v$ is $\mathbf{x}_v$.

GNNs learn node representations through iterative \emph{message passing}. At each layer $t$, a node updates its representation by aggregating information from its neighbours:
\begin{equation}
  \mathbf{h}_v^{(t)} = \text{UPDATE}\!\left(\mathbf{h}_v^{(t-1)},\; \text{AGGREGATE}\!\left(\left\{\!\left\{\mathbf{h}_u^{(t-1)} : u \in \mathcal{N}(v)\right\}\!\right\}\right)\right),
  \label{eq:mp}
\end{equation}
where $\mathcal{N}(v) = \{u \in V : (u,v) \in E\}$ denotes the neighbourhood of $v$, $\mathbf{h}_v^{(0)} = \mathbf{x}_v$ is the initial node feature, and $\{\!\{\cdot\}\!\}$ denotes a multiset.

The choice of UPDATE and AGGREGATE functions determines the specific GNN variant. In our implementation, these are parameterised by separate linear transformations for the self-feature and the aggregated neighbour features. After $T$ layers of message passing, a \emph{readout} function pools all node embeddings into a single graph-level representation:
\begin{equation}
  \mathbf{h}_G = \text{READOUT}\!\left(\left\{\mathbf{h}_v^{(T)} : v \in V\right\}\right).
  \label{eq:readout}
\end{equation}
Common choices for READOUT include sum, mean, and max pooling over the node set. We use sum pooling throughout this work, as it preserves information about both the features and the number of nodes.

\subsection{The $k$-WL Hierarchy and $k$-GNNs}

The \emph{Weisfeiler--Leman} (WL) graph isomorphism test is a classical algorithm that iteratively refines node colour labels based on the multiset of neighbour colours. Two graphs are distinguished if, after some number of iterations, they produce different multisets of colours. The 1-WL test operates on individual nodes.

A fundamental result in GNN theory is that standard message-passing GNNs are \emph{at most} as powerful as the 1-WL test~\cite{morris2019weisfeiler}: if 1-WL cannot distinguish two graphs, no message-passing GNN can either. This means there exist structurally different graphs (e.g., certain regular graphs) that no standard GNN can tell apart.

The $k$-WL test generalises this by operating on $k$-tuples of nodes, achieving strictly increasing discriminative power: for all $k \geq 2$, $(k+1)$-WL is strictly more powerful than $k$-WL~\cite{cai1992optimal}. Morris et al.~\cite{morris2019weisfeiler} proposed $k$-GNNs that achieve this higher expressiveness by performing message passing on $k$-element subsets of nodes (``$k$-sets'') rather than individual nodes.

For a $k$-set $s = \{v_1, \ldots, v_k\} \subseteq V$, the \emph{local neighbourhood} is:
\begin{equation}
  \mathcal{N}_L(s) = \left\{s' \subseteq V : |s'| = k,\; |s \triangle s'| = 2,\; \text{the differing elements are adjacent in } G\right\},
  \label{eq:kset-nbr}
\end{equation}
where $s \triangle s'$ denotes the symmetric difference. In words: a neighbour of $s$ is obtained by replacing exactly one element of $s$ with a new node that is adjacent (in the original graph $G$) to the removed node.

\textbf{Example.} Consider a 2-set $s = \{u, v\}$. Its neighbours are all pairs $\{v, w\}$ where $(u,w) \in E$ (replacing $u$ with adjacent $w$) and all pairs $\{u, w\}$ where $(v,w) \in E$ (replacing $v$ with adjacent $w$). This means the 2-GNN can capture pairwise relationships and bond-level patterns that are invisible to a 1-GNN operating on individual nodes.

\subsection{GIN-Graph}

GIN-Graph~\cite{sun2025gingraph} is a model-level explanation method that generates class-representative graphs using a generative adversarial approach. The key idea is to train a generator $\mathcal{G}$ to produce graphs that satisfy two objectives simultaneously:
\begin{enumerate}[nosep]
  \item \textbf{Realism}: generated graphs should be structurally similar to real graphs from the dataset, enforced by a WGAN-GP discriminator.
  \item \textbf{Class specificity}: generated graphs should be confidently classified as the target class by the pretrained GNN, enforced by a classification guidance loss.
\end{enumerate}

The generator maps noise $\mathbf{z} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$ to a graph $(\tilde{A}, \tilde{X})$ using Gumbel-Softmax for differentiable discrete sampling. The training objective balances the two losses through a dynamic weighting schedule that shifts focus from realism (early training) to class specificity (late training).

% ============================================================
% 3. Method
% ============================================================
\section{Method}
\label{sec:method}

This section details the mathematical formulations of our two classifier architectures (1-GNN and 1-2-GNN), the GIN-Graph generator, the training procedure, and the differentiable dense wrapper that bridges them.

\subsection{1-GNN Architecture}

Our 1-GNN implements message passing with separate transformations for self-features and neighbour-aggregated features. At layer $t$, the update rule for node $v$ is:
\begin{equation}
  \mathbf{h}_v^{(t)} = \sigma\!\left(\mathbf{h}_v^{(t-1)} \mathbf{W}_1^{(t)} + \sum_{u \in \mathcal{N}(v)} \mathbf{h}_u^{(t-1)} \mathbf{W}_2^{(t)}\right),
  \label{eq:1gnn}
\end{equation}
where $\mathbf{W}_1^{(t)}, \mathbf{W}_2^{(t)} \in \mathbb{R}^{d_{t-1} \times d_t}$ are learnable weight matrices, $\sigma$ is the ReLU activation function $\sigma(x) = \max(0, x)$, and $d_0 = d$ (the input feature dimension). The self-transformation $\mathbf{h}_v^{(t-1)} \mathbf{W}_1^{(t)}$ allows the model to retain and transform the node's own representation, while the neighbour term $\sum_{u \in \mathcal{N}(v)} \mathbf{h}_u^{(t-1)} \mathbf{W}_2^{(t)}$ aggregates structural context.

This can equivalently be written in matrix form for the entire graph:
\begin{equation}
  \mathbf{H}^{(t)} = \sigma\!\left(\mathbf{H}^{(t-1)} \mathbf{W}_1^{(t)} + \mathbf{A}\,\mathbf{H}^{(t-1)} \mathbf{W}_2^{(t)}\right),
  \label{eq:1gnn-matrix}
\end{equation}
where $\mathbf{H}^{(t)} \in \mathbb{R}^{n \times d_t}$ is the matrix of all node representations at layer $t$, and $\mathbf{A} \in \{0,1\}^{n \times n}$ is the adjacency matrix. The matrix product $\mathbf{A}\,\mathbf{H}^{(t-1)}$ computes the sum of neighbour features for every node simultaneously.

After $T = 3$ layers with hidden dimension $d_1 = d_2 = d_3 = 64$, the graph embedding is obtained via sum pooling:
\begin{equation}
  \mathbf{h}_G^{(1)} = \sum_{v \in V} \mathbf{h}_v^{(T)} \in \mathbb{R}^{d_T}.
  \label{eq:1gnn-readout}
\end{equation}

This embedding is fed through a two-layer classifier MLP with ReLU activation and dropout:
\begin{equation}
  \hat{y} = \text{softmax}\!\left(\mathbf{W}_o\,\sigma(\mathbf{W}_c\,\mathbf{h}_G^{(1)})\right),
  \label{eq:classifier}
\end{equation}
where $\mathbf{W}_c \in \mathbb{R}^{d_T \times d_T}$ and $\mathbf{W}_o \in \mathbb{R}^{d_T \times C}$ with $C$ being the number of classes.

\subsection{2-GNN and the Hierarchical 1-2-GNN}
\label{sec:2gnn}

The 2-GNN operates on 2-sets (unordered node pairs) rather than individual nodes. For each pair $s = \{u, v\}$ with $u < v$ (canonical ordering), the initial feature vector incorporates the 1-GNN embeddings of both nodes and an \emph{isomorphism type} indicator:
\begin{equation}
  \mathbf{f}_s^{(0)} = \left[\mathbf{h}_u^{(T)} \;\|\; \mathbf{h}_v^{(T)} \;\|\; \mathbb{1}[(u,v) \in E]\right] \in \mathbb{R}^{2d_T + 1},
  \label{eq:2set-feat}
\end{equation}
where $\|$ denotes vector concatenation. The isomorphism type $\mathbb{1}[(u,v) \in E] \in \{0, 1\}$ indicates whether $u$ and $v$ are connected by an edge. This is crucial because it allows the 2-GNN to distinguish between pairs of connected nodes and pairs of unconnected nodes---a distinction that carries structural meaning (e.g., in a molecule, bonded vs.\ non-bonded atom pairs).

Message passing on 2-sets follows the neighbourhood definition from Equation~\eqref{eq:kset-nbr}. For a 2-set $s = \{u, v\}$, the local neighbourhood decomposes into two cases:
\begin{equation}
  \mathcal{N}_L(\{u, v\}) = \underbrace{\left\{\{v, w\} : w \neq u,\; (u, w) \in E\right\}}_{\text{Case 1: replace } u \text{ with } w} \cup \underbrace{\left\{\{u, w\} : w \neq v,\; (v, w) \in E\right\}}_{\text{Case 2: replace } v \text{ with } w}.
  \label{eq:2set-nbr}
\end{equation}
In Case 1, we remove $u$ from the pair and add a new node $w$ that must be adjacent to $u$ in the original graph. In Case 2, we remove $v$ and add $w$ adjacent to $v$. This ensures that neighbourhood relationships in the 2-GNN reflect the edge structure of the underlying graph.

The 2-GNN layer update rule mirrors the 1-GNN structure:
\begin{equation}
  \mathbf{f}_s^{(\ell+1)} = \sigma\!\left(\mathbf{f}_s^{(\ell)} \mathbf{W}_3^{(\ell)} + \sum_{s' \in \mathcal{N}_L(s)} \mathbf{f}_{s'}^{(\ell)} \mathbf{W}_4^{(\ell)}\right),
  \label{eq:2gnn-update}
\end{equation}
where $\mathbf{W}_3^{(\ell)}, \mathbf{W}_4^{(\ell)}$ are the 2-GNN weight matrices at layer $\ell$. We apply $T_2 = 2$ layers.

The \textbf{hierarchical 1-2-GNN} combines both levels. It first runs the 1-GNN (Equation~\ref{eq:1gnn}) for $T_1 = 3$ layers to obtain node embeddings, then uses these embeddings to initialise 2-GNN features (Equation~\ref{eq:2set-feat}), and runs $T_2 = 2$ layers of 2-GNN message passing. The final graph representation concatenates both readouts:
\begin{equation}
  \mathbf{h}_G = \left[\mathbf{h}_G^{(1)} \;\|\; \mathbf{h}_G^{(2)}\right] \in \mathbb{R}^{2d_T},
  \label{eq:12gnn-readout}
\end{equation}
where the 1-GNN readout is $\mathbf{h}_G^{(1)} = \sum_{v \in V} \mathbf{h}_v^{(T_1)}$ and the 2-GNN readout pools over all pairs:
\begin{equation}
  \mathbf{h}_G^{(2)} = \sum_{\{u,v\} \in \binom{V}{2}} \mathbf{f}_{\{u,v\}}^{(T_2)} \in \mathbb{R}^{d_T}.
  \label{eq:2gnn-readout}
\end{equation}
The concatenated embedding $\mathbf{h}_G$ is then fed through the same classifier structure as Equation~\eqref{eq:classifier}, but with input dimension $2d_T$ instead of $d_T$.

\textbf{Scalability.} The number of 2-sets grows as $\binom{n}{2} = \frac{n(n-1)}{2}$, which becomes prohibitive for large graphs. For PROTEINS (up to 620 nodes, yielding up to 191,890 pairs), we randomly sample up to 5000 pairs per graph. This preserves a representative sample of pairwise interactions while keeping computation tractable.

\subsection{GIN-Graph Generator}
\label{sec:generator}

The generator $\mathcal{G}$ maps a latent noise vector $\mathbf{z} \in \mathbb{R}^{d_z}$ to a graph $(\tilde{A}, \tilde{X})$ through a backbone MLP followed by separate output heads:
\begin{align}
  \mathbf{h} &= \text{LeakyReLU}\!\left(\mathbf{W}_2\,\text{LeakyReLU}(\mathbf{W}_1 \mathbf{z})\right) \in \mathbb{R}^{2d_h}, \label{eq:gen-backbone} \\
  \tilde{A}_{\text{raw}} &= \text{sym}\!\left(\text{reshape}(\mathbf{h}\,\mathbf{W}_A,\; N \times N)\right), \label{eq:gen-adj-raw} \\
  \tilde{X}_{\text{raw}} &= \text{reshape}(\mathbf{h}\,\mathbf{W}_X,\; N \times D), \label{eq:gen-feat-raw}
\end{align}
where $d_z = 32$ is the latent dimension, $d_h = 128$ is the hidden dimension, $N$ is the maximum number of nodes, $D$ is the number of node feature types, and $\text{sym}(\mathbf{M}) = \frac{1}{2}(\mathbf{M} + \mathbf{M}^\top)$ ensures the adjacency logits are symmetric (undirected graphs).

\textbf{Gumbel-Softmax.} Graphs are inherently discrete objects: edges are either present or absent, and node types are categorical. Standard gradient-based optimisation cannot backpropagate through discrete sampling. The Gumbel-Softmax trick~\cite{jang2017categorical} provides a differentiable relaxation.

For a categorical distribution with unnormalised log-probabilities (logits) $\pi_1, \ldots, \pi_K$, the Gumbel-Softmax sample is:
\begin{equation}
  y_i = \frac{\exp\!\left((\pi_i + g_i) / \tau\right)}{\sum_{j=1}^{K} \exp\!\left((\pi_j + g_j) / \tau\right)}, \quad g_i = -\log(-\log(u_i)), \quad u_i \sim \text{Uniform}(0,1),
  \label{eq:gumbel}
\end{equation}
where $\tau > 0$ is a temperature parameter. As $\tau \to 0$, the output approaches a one-hot vector (hard categorical sample); as $\tau \to \infty$, it approaches a uniform distribution. During training, we use the \emph{straight-through estimator}: the forward pass produces hard (discrete) samples via $\arg\max$, but the backward pass uses the continuous Gumbel-Softmax gradients. This gives the generator discrete outputs while maintaining gradient flow.

For the \textbf{adjacency matrix}, each potential edge $(i,j)$ is a binary choice (edge/no-edge). We construct 2-class logits $[\tilde{A}_{\text{raw}}[i,j],\; -\tilde{A}_{\text{raw}}[i,j]]$ and apply Gumbel-Softmax with $K=2$. To guarantee symmetry ($\tilde{A}_{ij} = \tilde{A}_{ji}$), we sample only the upper triangle and mirror it:
\begin{equation}
  \tilde{A}_{\text{upper}} = \text{triu}(\text{GumbelSoftmax}(\tilde{A}_{\text{raw}}, \tau)), \quad
  \tilde{A} = \tilde{A}_{\text{upper}} + \tilde{A}_{\text{upper}}^\top.
  \label{eq:adj-symmetry}
\end{equation}

For \textbf{node features}, each node has $D$ possible types (e.g., 7 atom types for MUTAG). We apply Gumbel-Softmax with $K=D$ to produce one-hot feature vectors:
\begin{equation}
  \tilde{X}[v,:] = \text{GumbelSoftmax}(\tilde{X}_{\text{raw}}[v,:],\; \tau) \in \{0,1\}^D.
  \label{eq:feat-gumbel}
\end{equation}

The temperature $\tau = 1.0$ during training (allowing exploration) and $\tau = 0.1$ during evaluation (producing sharper, more discrete outputs).

\subsection{Training Objective}
\label{sec:training}

The total generator loss combines adversarial and GNN-guidance terms:
\begin{equation}
  \mathcal{L}_G = (1 - \lambda(t))\,\mathcal{L}_{\text{GAN}} + \lambda(t)\,\mathcal{L}_{\text{GNN}},
  \label{eq:total-loss}
\end{equation}
where $\lambda(t) \in [0, 1]$ is a dynamic weight that increases over training.

\textbf{WGAN-GP loss.} We use a Wasserstein GAN with gradient penalty~\cite{gulrajani2017improved}. The discriminator $\mathcal{D}$ (a GNN-based network) estimates the Wasserstein distance between real and generated graph distributions. The discriminator loss is:
\begin{equation}
  \mathcal{L}_D = \underbrace{\mathbb{E}_{\tilde{G} \sim \mathcal{G}}[\mathcal{D}(\tilde{G})]}_{\text{score on fake}} - \underbrace{\mathbb{E}_{G \sim p_{\text{data}}}[\mathcal{D}(G)]}_{\text{score on real}} + \underbrace{\lambda_{\text{GP}} \, \mathbb{E}_{\hat{G}}\!\left[(\|\nabla_{\hat{G}} \mathcal{D}(\hat{G})\|_2 - 1)^2\right]}_{\text{gradient penalty}},
  \label{eq:wgan-d}
\end{equation}
where $\hat{G} = \epsilon G + (1 - \epsilon)\tilde{G}$ with $\epsilon \sim \text{Uniform}(0,1)$ is a random interpolation, and $\lambda_{\text{GP}} = 10$. The gradient penalty enforces the Lipschitz constraint on $\mathcal{D}$, stabilising training. The generator's adversarial loss is simply:
\begin{equation}
  \mathcal{L}_{\text{GAN}} = -\mathbb{E}_{\tilde{G} \sim \mathcal{G}}[\mathcal{D}(\tilde{G})].
  \label{eq:wgan-g}
\end{equation}

\textbf{GNN guidance loss.} We maximise the pretrained classifier's confidence on the target class $c$:
\begin{equation}
  \mathcal{L}_{\text{GNN}} = -\log p_\Phi(y = c \mid \tilde{G}),
  \label{eq:gnn-loss}
\end{equation}
where $p_\Phi(y = c \mid \tilde{G})$ is the softmax probability assigned to class $c$ by the pretrained $k$-GNN $\Phi$. Minimising this loss pushes the generator to produce graphs that the classifier recognises as belonging to class $c$.

\textbf{Dynamic weighting.} The balance parameter $\lambda(t)$ follows a sigmoid schedule~\cite{sun2025gingraph}:
\begin{equation}
  \lambda(t) = \lambda_{\min} + (\lambda_{\max} - \lambda_{\min}) \cdot \sigma\!\left(k \cdot \left(\frac{2(t/T - p)}{1-p} - 1\right)\right),
  \label{eq:lambda}
\end{equation}
where $T$ is the total number of training iterations, $p = 0.4$ is the fraction of training before $\lambda$ begins increasing, $k = 10$ controls the steepness of the transition, and $\sigma(x) = 1/(1 + e^{-x})$ is the logistic sigmoid.

The intuition is as follows. When $t \ll pT$, the sigmoid argument is strongly negative, giving $\lambda(t) \approx 0$: the generator focuses on learning realistic graph structure (GAN loss dominates). As $t$ passes $pT$, $\lambda(t)$ increases rapidly toward 1: the generator shifts to producing class-specific patterns (GNN loss dominates). Without this schedule, the generator would collapse to structurally degenerate graphs that fool the classifier but look nothing like real molecules or proteins.

\subsection{Dense Wrapper for Differentiable $k$-GNN Inference}
\label{sec:dense-wrapper}

A key technical challenge is that the pretrained $k$-GNN uses sparse PyTorch Geometric message-passing operations (scatter-add on edge lists), while the generator outputs dense adjacency matrices $\tilde{A} \in [0,1]^{N \times N}$ that require gradient flow for backpropagation. We implement a fully differentiable \emph{dense wrapper} that re-implements the $k$-GNN forward pass using dense matrix operations while reusing the pretrained weights (which are frozen).

\textbf{Dense 1-GNN.} The node-level update (Equation~\ref{eq:1gnn-matrix}) translates directly to dense batched computation. For a batch of $B$ graphs with node features $\mathbf{X} \in \mathbb{R}^{B \times N \times d}$ and adjacency $\mathbf{A} \in [0,1]^{B \times N \times N}$:
\begin{equation}
  \mathbf{H}^{(t)} = \sigma\!\left(\mathbf{H}^{(t-1)} \mathbf{W}_1^{(t)} + \mathbf{A} \, \mathbf{H}^{(t-1)} \mathbf{W}_2^{(t)}\right),
  \label{eq:dense-1gnn}
\end{equation}
where the batch dimension is broadcast. The matrix product $\mathbf{A} \, \mathbf{H}^{(t-1)}$ replaces the sparse scatter-add operation and is fully differentiable with respect to the continuous $\mathbf{A}$. Crucially, the weights $\mathbf{W}_1^{(t)}, \mathbf{W}_2^{(t)}$ are copied from the pretrained sparse model and kept frozen.

\textbf{Dense 2-GNN.} The 2-GNN component requires constructing pair features and aggregating over 2-set neighbourhoods, both as dense operations. We represent all $\binom{N}{2}$ pair features as an $N \times N$ tensor (using only the upper triangle for the canonical pairs).

First, we construct the pair features from the 1-GNN node embeddings $\mathbf{H}^{(T_1)} \in \mathbb{R}^{B \times N \times d_T}$:
\begin{equation}
  \mathbf{F}[i,j] = \left[\mathbf{h}_{\min(i,j)} \;\|\; \mathbf{h}_{\max(i,j)} \;\|\; A_{ij}\right] \in \mathbb{R}^{2d_T + 1},
  \label{eq:dense-2gnn-feat}
\end{equation}
where the canonical ordering $(\min, \max)$ ensures that $\mathbf{F}[i,j] = \mathbf{F}[j,i]$, matching the unordered pair semantics. The isomorphism type $A_{ij}$ is the continuous adjacency value from the generator, maintaining differentiability.

For the neighbourhood aggregation, recall from Equation~\eqref{eq:2set-nbr} that there are two cases. Using the transformed features $\mathbf{g} = \mathbf{F}\,\mathbf{W}_4^{(\ell)} \in \mathbb{R}^{B \times N \times N \times d_T}$, the aggregation for pair $(i,j)$ is:
\begin{align}
  \text{agg}_1[i,j] &= \sum_{\substack{w=1 \\ w \neq j}}^{N} A_{iw} \cdot \mathbf{g}[j,w] & &\text{(replace } i \text{ with } w \text{ adjacent to } i\text{)}, \label{eq:dense-2gnn-agg1} \\
  \text{agg}_2[i,j] &= \sum_{\substack{w=1 \\ w \neq i}}^{N} A_{jw} \cdot \mathbf{g}[i,w] & &\text{(replace } j \text{ with } w \text{ adjacent to } j\text{)}. \label{eq:dense-2gnn-agg2}
\end{align}

The constraints $w \neq j$ in $\text{agg}_1$ and $w \neq i$ in $\text{agg}_2$ are essential: without them, the summation includes the self-pair $\{j,j\}$ or $\{i,i\}$, which has cardinality 1 and is not a valid 2-set. The self-loop exclusion ($A_{ii} = 0$) already removes $w = i$ from $\text{agg}_1$ and $w = j$ from $\text{agg}_2$, but the opposite boundary terms must be explicitly masked. In practice, we zero out the diagonal of $\mathbf{g}$ (setting $\mathbf{g}[k,k] = \mathbf{0}$ for all $k$) before the summation, which eliminates both boundary terms simultaneously.

These sums are computed efficiently via Einstein summation (\texttt{einsum}) over the masked $\mathbf{g}$. The key insight is that multiplying by $A_{iw}$ (a continuous value from the generator) acts as a soft attention over potential neighbours, and gradients flow through $\mathbf{A}$ into the generator. The full 2-GNN layer update is then:
\begin{equation}
  \mathbf{F}^{(\ell+1)} = \sigma\!\left(\mathbf{F}^{(\ell)}\,\mathbf{W}_3^{(\ell)} + \text{agg}_1^{(\ell)} + \text{agg}_2^{(\ell)}\right).
  \label{eq:dense-2gnn-update}
\end{equation}

After $T_2$ layers, the 2-GNN readout sums over the upper-triangular entries:
\begin{equation}
  \mathbf{h}_G^{(2)} = \sum_{i < j} \mathbf{F}^{(T_2)}[i,j].
  \label{eq:dense-2gnn-pool}
\end{equation}

Both the 1-GNN and 2-GNN dense paths are fully differentiable through $\mathbf{A}$, enabling the generator to learn how edge structure affects the classifier's output at both the node and pair level.

\subsection{Validation Score}
\label{sec:validation}

We evaluate generated explanations using a composite validation score~\cite{sun2025gingraph}:
\begin{equation}
  v = (s \cdot p \cdot d)^{1/3},
  \label{eq:validation}
\end{equation}
comprising three components. The geometric mean ensures that all three aspects must be satisfied: a graph cannot achieve a high score if it fails on any single component.

\textbf{Embedding similarity} ($s$). The cosine similarity between the generated graph's embedding (computed via the dense wrapper) and a \emph{class centroid}---the mean embedding of all real graphs in the target class, computed via the sparse $k$-GNN on the training set:
\begin{equation}
  s = \cos(\mathbf{h}_{\tilde{G}},\, \boldsymbol{\mu}_c) = \frac{\mathbf{h}_{\tilde{G}} \cdot \boldsymbol{\mu}_c}{\|\mathbf{h}_{\tilde{G}}\| \, \|\boldsymbol{\mu}_c\|}, \quad \text{where } \boldsymbol{\mu}_c = \frac{1}{|\mathcal{G}_c|} \sum_{G \in \mathcal{G}_c} \mathbf{h}_G.
  \label{eq:emb-sim}
\end{equation}
This measures whether the generated graph ``looks like'' a real class member in the model's learned representation space. The centroid $\boldsymbol{\mu}_c$ is computed once and stored in the GIN-Graph checkpoint.

\textbf{Note on the corrected metric.} The original GIN-Graph implementation used the prediction probability $p$ as a proxy for embedding similarity (effectively setting $s = p$), which collapsed the validation score to $v = (p^2 \cdot d)^{1/3}$. We corrected this by computing actual cosine similarity via the dense wrapper's \texttt{get\_embedding()} method.

\textbf{Prediction probability} ($p$). The softmax probability assigned to the target class by the pretrained classifier: $p = p_\Phi(y = c \mid \tilde{G})$.

\textbf{Degree score} ($d$). A Gaussian kernel measuring how realistic the graph's average degree is relative to the target class:
\begin{equation}
  d = \exp\!\left(-\frac{(\bar{d}_{\tilde{G}} - \mu_d)^2}{2\sigma_d^2}\right),
  \label{eq:degree}
\end{equation}
where $\bar{d}_{\tilde{G}} = 2|\tilde{E}|/|\tilde{V}|$ is the average degree of the generated graph, and $\mu_d, \sigma_d$ are the mean and standard deviation of average degrees across real graphs in the target class. A graph with average degree close to the class mean receives $d \approx 1$; one with atypical degree is penalised exponentially.

A generated graph is considered \textbf{valid} if its average degree falls within 3 standard deviations of the class mean and its validation score exceeds 0.5.

\textbf{Granularity} ($\kappa$). We additionally report:
\begin{equation}
  \kappa = 1 - \min\!\left(1,\; \frac{n_{\tilde{G}}}{\bar{n}_c}\right),
  \label{eq:granularity}
\end{equation}
where $n_{\tilde{G}}$ is the number of active (non-isolated) nodes in the explanation and $\bar{n}_c$ is the average number of nodes in class $c$. Values near 0 indicate coarse-grained explanations (graph-sized); values near 1 would indicate fine-grained substructure highlights.

% ============================================================
% 4. Experimental Setup
% ============================================================
\section{Experimental Setup}
\label{sec:setup}

\subsection{Datasets}

We evaluate on two standard graph classification benchmarks (Table~\ref{tab:datasets}).

\begin{table}[htbp]
\centering
\caption{Dataset statistics. GIN Gen is the maximum number of nodes used for explanation generation.}
\label{tab:datasets}
\begin{tabular}{lccccl}
\toprule
\textbf{Dataset} & \textbf{Graphs} & \textbf{Node Feats} & \textbf{Max Nodes} & \textbf{GIN Gen} & \textbf{Task} \\
\midrule
MUTAG    & 188  & 7 (atom types) & 28  & 28 & Mutagenicity \\
PROTEINS & 1113 & 3 (sec.\ struct.) & 620 & 50 & Enzyme vs.\ non-enzyme \\
\bottomrule
\end{tabular}
\end{table}

\textbf{MUTAG}~\cite{debnath1991structure} contains 188 molecular graphs labelled by mutagenic effect on \textit{Salmonella typhimurium}. Nodes represent atoms (C, N, O, F, I, Cl, Br) and edges represent chemical bonds. The two classes are \emph{Mutagen} (class 0, 125 graphs) and \emph{Non-Mutagen} (class 1, 63 graphs).

\textbf{PROTEINS}~\cite{borgwardt2005protein} contains 1113 protein graphs where nodes are secondary structure elements (helix, sheet, coil/turn) connected if they are neighbours in the amino acid sequence or within a distance threshold in 3D space. The classes are \emph{Non-Enzyme} (class 0) and \emph{Enzyme} (class 1). For GIN-Graph generation, we cap the graph size at 50 nodes (the median protein graph has $\sim$26 nodes), as the explanations highlight key substructures rather than reproducing entire large graphs.

\subsection{Model Configuration}

All $k$-GNN models use a hidden dimension of $d_T = 64$. The 1-GNN uses $T_1 = 3$ message-passing layers; the 1-2-GNN uses 3 layers for the 1-GNN component and $T_2 = 2$ layers for the 2-GNN component. Both use dropout of 0.5 and are trained with Adam (lr = 0.01) for 100 epochs with cross-entropy loss. Data is split 80/20 into train/test with a fixed seed of 42.

The GIN-Graph generator uses a latent dimension $d_z = 32$, hidden dimension $d_h = 128$, and is trained for 300 epochs with Adam (lr = 0.001) and batch size 64. WGAN-GP uses $\lambda_{\text{GP}} = 10$ and trains the discriminator once per generator update ($n_{\text{critic}} = 1$). The dynamic weighting uses $p = 0.4$, $k = 10$, $\lambda_{\min} = 0$, $\lambda_{\max} = 1$.

\subsection{Evaluation Protocol}

For each model-dataset-class combination, we generate 100 explanation graphs at evaluation temperature $\tau = 0.1$ and evaluate them using the validation score (Equation~\ref{eq:validation}). We report:
\begin{itemize}[nosep]
  \item \textbf{Validity rate}: fraction of explanations passing degree and score thresholds;
  \item \textbf{Mean validation score}: averaged over all 100 generated graphs;
  \item \textbf{Component scores}: embedding similarity ($s$), prediction probability ($p$), degree score ($d$);
  \item \textbf{Granularity}: how fine-grained the explanations are.
\end{itemize}

% ============================================================
% 5. Results
% ============================================================
\section{Results}
\label{sec:results}

\subsection{$k$-GNN Classification Performance}

Table~\ref{tab:kgnn-results} summarises the classification results. On MUTAG, both models achieve identical best test accuracy of 89.5\%, indicating that the additional pairwise message passing does not provide a classification advantage on this small molecular dataset. On PROTEINS, the 1-GNN significantly outperforms the 1-2-GNN (77.6\% vs.\ 68.6\%). The 1-2-GNN has 2.3$\times$ more parameters (50,370 vs.\ 21,570), and on the relatively simple 3-dimensional node features of PROTEINS, this additional capacity leads to overfitting---the 1-2-GNN's best accuracy occurs at epoch 2, with no further improvement, suggesting the model fails to learn meaningful representations.

\begin{table}[htbp]
\centering
\caption{$k$-GNN classification results. Best test accuracy reported over all epochs.}
\label{tab:kgnn-results}
\begin{tabular}{llcccc}
\toprule
\textbf{Dataset} & \textbf{Model} & \textbf{Params} & \textbf{Final Test Acc} & \textbf{Best Acc} & \textbf{Best Epoch} \\
\midrule
MUTAG    & 1-GNN   & 21,570 & 81.6\% & 89.5\% & 59 \\
MUTAG    & 1-2-GNN & 50,370 & 86.8\% & 89.5\% & 55 \\
\midrule
PROTEINS & 1-GNN   & 21,058 & 75.3\% & 77.6\% & 33 \\
PROTEINS & 1-2-GNN & 49,858 & 62.8\% & 68.6\% & 2 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{GIN-Graph Explanation Quality: MUTAG}

Table~\ref{tab:gin-mutag} presents the GIN-Graph results on MUTAG. All configurations were fully trained for 300 epochs, enabling fair cross-model comparison on both classes.

\begin{table}[htbp]
\centering
\caption{GIN-Graph explanation quality on MUTAG. All models trained for 300 epochs.}
\label{tab:gin-mutag}
\begin{tabular}{llccccc}
\toprule
\textbf{Class} & \textbf{Model} & \textbf{Valid\%} & \textbf{Val Score} & $s$ & $p$ & $d$ \\
\midrule
0 (Mutagen)     & 1-GNN   & 36\% & 0.377 & 0.600 & 1.000 & 0.271 \\
0 (Mutagen)     & 1-2-GNN & 35\% & 0.362 & 0.893 & 0.627 & 0.260 \\
\midrule
1 (Non-Mutagen) & 1-GNN   & 82\% & 0.706 & 0.965 & 1.000 & 0.504 \\
1 (Non-Mutagen) & 1-2-GNN & \textbf{92\%} & \textbf{0.801} & \textbf{0.979} & 1.000 & \textbf{0.621} \\
\bottomrule
\end{tabular}
\end{table}

On class 1 (Non-Mutagen), the 1-2-GNN produces explanations with higher validity (92\% vs.\ 82\%), higher validation scores (0.801 vs.\ 0.706), and notably higher degree scores (0.621 vs.\ 0.504), indicating more structurally realistic graphs. This advantage is particularly striking because both models achieve identical classification accuracy (89.5\%), isolating the effect of higher-order message passing on explanation quality from classification performance.

On class 0 (Mutagen), both models struggle equally ($\sim$35\% validity), suggesting that the Mutagen class is inherently harder to generate. This difficulty likely stems from two factors: class imbalance (Non-Mutagen is the majority class at 125/188 = 66.5\%, providing the generator with more real examples to learn from) and structural diversity (mutagenic compounds exhibit varied functional groups---nitro, amino, halogen---making a single representative graph harder to produce). The 1-2-GNN achieves higher embedding similarity (0.893 vs.\ 0.600) but lower prediction probability (0.627 vs.\ 1.000), indicating a tension between embedding-space fidelity and classification confidence.

Qualitatively, the two models generate strikingly different atom type distributions for class 0 (Figure~\ref{fig:mutag-class0}). The 1-GNN produces C/N/O-dominated structures (49\% C, 25\% N, 25\% O) consistent with nitrogen-containing mutagenic motifs, while the 1-2-GNN generates halogen-heavy graphs dominated by fluorine and oxygen (36\% F, 34\% O, 20\% Cl)---suggesting that the pairwise message passing leads the model to associate mutagenicity with halogenated structures rather than nitroaromatic ones. This divergence reveals that the two architectures learn qualitatively different internal representations of the same class.

\begin{figure}[htbp]
\centering
\begin{subfigure}[t]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{results/mutag/1gnn_class0/figures/explanations.png}
  \caption{1-GNN explanations for Mutagen}
  \label{fig:mutag-1gnn-c0}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{results/mutag/12gnn_class0/figures/explanations.png}
  \caption{1-2-GNN explanations for Mutagen}
  \label{fig:mutag-12gnn-c0}
\end{subfigure}
\caption{Top-ranked GIN-Graph explanations on MUTAG class 0 (Mutagen). The 1-GNN generates C/N/O-rich structures (orange/blue/red), while the 1-2-GNN produces halogen-heavy graphs dominated by F and O (green/red). Node colours indicate atom types (see Figure~\ref{fig:legend}).}
\label{fig:mutag-class0}
\end{figure}

Figure~\ref{fig:mutag-explanations} shows the top-ranked explanation graphs for both models on MUTAG class 1.

\begin{figure}[htbp]
\centering
\begin{subfigure}[t]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{results/mutag/1gnn_class1/figures/explanations.png}
  \caption{1-GNN explanations for Non-Mutagen}
  \label{fig:mutag-1gnn}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{results/mutag/12gnn_class1/figures/explanations.png}
  \caption{1-2-GNN explanations for Non-Mutagen}
  \label{fig:mutag-12gnn}
\end{subfigure}
\caption{Top-ranked GIN-Graph explanations on MUTAG class 1 (Non-Mutagen). Node colours indicate atom types (see Figure~\ref{fig:legend}).}
\label{fig:mutag-explanations}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=0.5\textwidth]{results/mutag/1gnn_class1/figures/mutag_legend.png}
\caption{MUTAG atom type colour legend. Atoms: C (orange), N (blue), O (red), F (green), I (purple), Cl (light green), Br (brown).}
\label{fig:legend}
\end{figure}

The top 1-2-GNN explanations achieve near-perfect validation scores (0.997), with consistent graph sizes (25--26 nodes, 28--29 edges). The 1-GNN explanations, while still high quality (top score 0.989), show slightly more structural variation.

\subsection{GIN-Graph Explanation Quality: PROTEINS}

Table~\ref{tab:gin-proteins} presents results on PROTEINS. All configurations were fully trained for 300 epochs. The 1-GNN produces substantially better explanations across both classes, consistent with its stronger classification performance.

\begin{table}[htbp]
\centering
\caption{GIN-Graph explanation quality on PROTEINS. All models trained for 300 epochs.}
\label{tab:gin-proteins}
\begin{tabular}{llccccc}
\toprule
\textbf{Class} & \textbf{Model} & \textbf{Valid\%} & \textbf{Val Score} & $s$ & $p$ & $d$ \\
\midrule
0 (Non-Enzyme)  & \textbf{1-GNN}   & \textbf{100\%} & \textbf{0.978} & 0.994 & \textbf{0.946} & 0.994 \\
0 (Non-Enzyme)  & 1-2-GNN          & 100\% & 0.831 & 0.999 & 0.581 & 0.988 \\
\midrule
1 (Enzyme)      & \textbf{1-GNN}   & \textbf{100\%} & \textbf{0.901} & 0.748 & \textbf{0.997} & 0.983 \\
1 (Enzyme)      & 1-2-GNN          & 100\% & 0.742 & 0.997 & 0.419 & 0.979 \\
\bottomrule
\end{tabular}
\end{table}

Both models achieve 100\% validity on PROTEINS, reflecting the more regular degree distributions in protein graphs. However, the 1-GNN produces substantially higher validation scores (0.978 and 0.901 vs.\ 0.831 and 0.742). The critical difference lies in the prediction probability: the 1-GNN generator produces graphs confidently classified as the target class ($p = 0.946$ and $0.997$), while the 1-2-GNN's prediction probabilities are frozen at 0.581 and 0.419---values that remain constant across all 100 generated graphs and closely mirror the class prior (59.6\% class 0, 40.4\% class 1). This indicates that the 1-2-GNN classifier outputs near-constant predictions regardless of input structure, meaning it has not learned discriminative features. Even with full 300-epoch GIN-Graph training, the generator cannot compensate for this fundamental classifier failure.

\begin{figure}[htbp]
\centering
\begin{subfigure}[t]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{results/proteins/1gnn_class0/figures/explanations.png}
  \caption{1-GNN explanations for Non-Enzyme}
  \label{fig:proteins-1gnn}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{results/proteins/1gnn_class1/figures/explanations.png}
  \caption{1-GNN explanations for Enzyme}
  \label{fig:proteins-1gnn-c1}
\end{subfigure}
\caption{Top-ranked GIN-Graph explanations on PROTEINS (1-GNN). Node colours indicate secondary structure types: helix (H, pink), sheet (S, teal), coil/turn (C, green).}
\label{fig:proteins-explanations}
\end{figure}

\begin{figure}[htbp]
\centering
\begin{subfigure}[t]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{results/proteins/12gnn_class0/figures/explanations.png}
  \caption{1-2-GNN explanations for Non-Enzyme}
  \label{fig:proteins-12gnn-c0}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.48\textwidth}
  \centering
  \includegraphics[width=\textwidth]{results/proteins/12gnn_class1/figures/explanations.png}
  \caption{1-2-GNN explanations for Enzyme}
  \label{fig:proteins-12gnn-c1}
\end{subfigure}
\caption{Top-ranked GIN-Graph explanations on PROTEINS (1-2-GNN). All class 0 graphs have identical validation scores ($v = 0.83$, $n = 41$) and all class 1 graphs score $v = 0.75$, visually illustrating the mode collapse caused by the frozen classifier.}
\label{fig:proteins-12gnn-explanations}
\end{figure}

The mode collapse of the 1-2-GNN is visually evident in Figure~\ref{fig:proteins-12gnn-explanations}: all 10 top class 0 explanations have identical validation scores ($v = 0.83$) and nearly identical node counts ($n = 41$), and all class 1 explanations score $v = 0.75$. By contrast, the 1-GNN explanations (Figure~\ref{fig:proteins-explanations}) show healthy variation ($v = 0.92$--$0.98$ for class 0, $v = 0.92$--$0.94$ for class 1), indicating that the generator is exploring diverse graph structures. This near-zero variance in the 1-2-GNN outputs provides direct visual confirmation that the collapsed classifier produces indistinguishable guidance regardless of the generated graph's structure.

\subsection{Metric Decomposition}

Table~\ref{tab:decomposition} provides a detailed comparison of the three validation score components across all configurations, now with all models trained for 300 epochs.

\begin{table}[htbp]
\centering
\caption{Validation score decomposition for all GIN-Graph models (300 epochs).}
\label{tab:decomposition}
\begin{tabular}{lllccc}
\toprule
\textbf{Dataset} & \textbf{Class} & \textbf{Model} & $s$ (emb.\ sim) & $p$ (pred.\ prob) & $d$ (degree) \\
\midrule
MUTAG & 0 (Mutagen)    & 1-GNN   & 0.600 & \textbf{1.000} & 0.271 \\
MUTAG & 0 (Mutagen)    & 1-2-GNN & \textbf{0.893} & 0.627 & 0.260 \\
\midrule
MUTAG & 1 (Non-Mut.)   & 1-GNN   & 0.965 & 1.000 & 0.504 \\
MUTAG & 1 (Non-Mut.)   & 1-2-GNN & \textbf{0.979} & 1.000 & \textbf{0.621} \\
\midrule
PROTEINS & 0 (Non-Enz.) & 1-GNN   & 0.994 & \textbf{0.946} & 0.994 \\
PROTEINS & 0 (Non-Enz.) & 1-2-GNN & 0.999 & 0.581 & 0.988 \\
\midrule
PROTEINS & 1 (Enzyme)   & 1-GNN   & 0.748 & \textbf{0.997} & 0.983 \\
PROTEINS & 1 (Enzyme)   & 1-2-GNN & 0.997 & 0.419 & 0.979 \\
\bottomrule
\end{tabular}
\end{table}

On MUTAG class 1, the degree score is the primary differentiator: the 1-2-GNN generates graphs whose average degree better matches the target class distribution (0.621 vs.\ 0.504). Both models achieve near-perfect prediction probability ($p \approx 1$), so this component does not discriminate. The embedding similarity, while high for both, is slightly closer to 1.0 for the 1-2-GNN (0.979 vs.\ 0.965).

On MUTAG class 0, an interesting asymmetry emerges: the 1-2-GNN achieves much higher embedding similarity (0.893 vs.\ 0.600) but at the cost of prediction probability (0.627 vs.\ 1.000). The 1-2-GNN's richer embedding space creates representations closer to the class centroid, but the generator struggles to simultaneously satisfy the classifier's decision boundary.

On PROTEINS, the prediction probability reveals the 1-2-GNN's failure mode most clearly. The 1-GNN achieves strong class-specific predictions ($p = 0.946$ for class 0, $p = 0.997$ for class 1), while the 1-2-GNN's predictions are frozen at $p = 0.581$ and $p = 0.419$---values near the dataset class prior that indicate the classifier has not learned discriminative features. Notably, the 1-2-GNN achieves near-perfect embedding similarity ($s > 0.99$) on PROTEINS, meaning the generated graphs lie close to the class centroid in embedding space but the classifier cannot distinguish them. The degree scores are uniformly high across all PROTEINS configurations ($d > 0.97$), indicating that structural realism is not the bottleneck.

The 1-GNN shows an asymmetry between PROTEINS classes: class 0 (Non-Enzyme) has near-perfect embedding similarity (0.994) while class 1 (Enzyme) has lower similarity (0.748). This suggests that the Enzyme class occupies a more complex region of the embedding space that the generator cannot fully capture.

\subsection{Training Dynamics}

Figure~\ref{fig:training} shows a representative training curve from the MUTAG 1-2-GNN class 1 experiment, illustrating the evolution of losses over 300 epochs.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.65\textwidth]{results/mutag/12gnn_class1/figures/training.png}
\caption{Training curves for GIN-Graph on MUTAG 1-2-GNN class 1, showing the evolution of generator loss, discriminator loss, and GNN guidance loss over 300 epochs.}
\label{fig:training}
\end{figure}

% ============================================================
% 6. Discussion
% ============================================================
\section{Discussion}
\label{sec:discussion}

\subsection{Does Higher-Order Message Passing Improve Explanations?}

Our results suggest a nuanced answer: \emph{it depends on the dataset, and explanation quality is fundamentally bounded by classifier quality}.

On MUTAG, both models achieve identical classification accuracy (89.5\%), yet the 1-2-GNN produces substantially better explanations: 92\% vs.\ 82\% validity and 0.80 vs.\ 0.71 validation score. This is a particularly clean comparison because the equal classification performance isolates the effect of higher-order message passing on explanation quality. The pairwise message passing enables the generator to produce graphs whose average degree better matches real molecules (degree score 0.621 vs.\ 0.504) and whose embeddings lie closer to the real class centroid (0.979 vs.\ 0.965). The 10 percentage point improvement in validity and the 0.10 improvement in validation score demonstrate that the 1-2-GNN's richer structural representations translate into more informative model-level explanations, even when both models classify equally well.

On PROTEINS, the situation is reversed. The 1-2-GNN fails to learn effective classification (68.6\%, below the 1-GNN's 77.6\%), with its best accuracy occurring at epoch 2---indicating the model never moves beyond its initial state. The prediction probabilities of generated graphs are frozen at 0.581 and 0.419 (close to the class prior of 59.6\%/40.4\%), confirming that the classifier outputs near-constant predictions. Consequently, the GIN-Graph generator cannot produce class-discriminative explanations from this collapsed classifier. This illustrates a fundamental coupling: \emph{explanation quality is bounded by classifier quality}. A model that does not understand the data cannot produce informative explanations, regardless of its theoretical expressiveness. The full 300-epoch GIN-Graph training confirms this is not an artifact of insufficient generator training---the bottleneck is the classifier itself.

\subsection{Qualitative Differences in Generated Explanations}

Beyond the quantitative metrics, the generated explanations reveal qualitative differences in what each model has learned. On MUTAG class 0 (Mutagen), the 1-GNN generates molecules dominated by carbon, nitrogen, and oxygen (49\% C, 25\% N, 25\% O)---atom types associated with classical mutagenic motifs such as nitroaromatic groups. The 1-2-GNN, by contrast, produces halogen-heavy structures dominated by fluorine and oxygen (36\% F, 34\% O, 20\% Cl), suggesting that its pairwise message passing leads it to associate mutagenicity with halogenated compounds. Both represent valid mutagenic subclasses, but the divergence demonstrates that the two architectures learn fundamentally different internal representations of the same chemical class.

On MUTAG class 1 (Non-Mutagen), both models converge on carbon-dominated backbones, though the 1-GNN includes substantial iodine presence while the 1-2-GNN produces more chemically conventional C/N/O structures. This convergence on the majority class is consistent with the higher validity rates: the Non-Mutagen class has more uniform structural patterns that the generator can capture.

On PROTEINS, both models generate visually similar secondary structure distributions (mixtures of helix, sheet, and coil nodes), which is expected given that the node features encode only three secondary structure types. The qualitative differences here are not in node composition but in structural diversity: the 1-GNN generates graphs with varied topologies (different connectivity patterns across the top 10 explanations), while the 1-2-GNN's outputs are nearly indistinguishable from each other---a visual signature of the collapsed classifier producing identical guidance signals.

\subsection{The Granularity Problem}

All generated explanations have granularity $\kappa \approx 0$, meaning they are as large as typical graphs in the dataset. This is a structural limitation of the GIN-Graph approach: the generator produces graphs of a fixed maximum size $N$, and the Gumbel-Softmax sampling tends to activate most nodes. For MUTAG ($N = 28$, average graph $\sim$18 nodes), the explanations use 20--27 nodes. For PROTEINS ($N = 50$, average graph $\sim$26 nodes), they use 45--50 nodes.

Model-level explanations are inherently coarse-grained: they answer ``what does a typical class member look like?'' rather than ``which substructure drives the prediction?'' This is a property of the method, not a flaw---the two questions require different explanation approaches.

\subsection{Limitations}

Several limitations qualify our findings:

\textbf{Single seed.} All experiments use a single data split (seed 42) without cross-validation. The small size of MUTAG (188 graphs, 38 in the test set) means that test accuracy can fluctuate by several percentage points across splits. The fact that both MUTAG models coincidentally achieve 89.5\% best accuracy may not hold across seeds.

\textbf{No cross-validation.} Best test accuracy is reported as the maximum over epochs (early stopping by oracle), which overestimates generalisation performance. The PROTEINS 1-2-GNN's best accuracy at epoch 2 (68.6\%) is particularly suspect, as it suggests the model's best performance is essentially random initialisation.

\textbf{Classifier dependence.} GIN-Graph explanations are fundamentally constrained by classifier quality. The PROTEINS 1-2-GNN comparison is confounded because the classifier itself underperforms, making it impossible to isolate the effect of higher-order message passing on explanation quality. The frozen prediction probabilities (0.581 and 0.419) confirm that the classifier has collapsed to near-constant output, rendering the GNN guidance loss ineffective.

\textbf{Evaluation metrics.} The validation score $v = (s \cdot p \cdot d)^{1/3}$ can be dominated by a single low component. The degree score, which measures structural realism via average degree alone, is a coarse proxy that does not capture finer structural properties like motif frequencies or degree distributions.

\subsection{Future Work}

Several directions could strengthen this investigation:
\begin{itemize}[nosep]
  \item Use cross-validation and multiple random seeds for robust accuracy and explanation quality estimates. The current single-seed results, while consistent across configurations, may not generalise.
  \item Investigate why the 1-2-GNN underperforms on PROTEINS---potential causes include overfitting due to the 2.3$\times$ parameter increase, sensitivity to hyperparameters, or the low feature dimensionality of PROTEINS (3 vs.\ 7 for MUTAG). Hyperparameter tuning (lower learning rate, stronger regularisation) or architectural modifications (shared instead of separate 1-GNN/2-GNN classifiers) may help.
  \item Extend to the 1-2-3-GNN architecture, which adds 3-set (triplet) message passing for even higher expressiveness, to test whether the interpretability benefit continues up the $k$-WL hierarchy.
  \item Incorporate richer structural evaluation metrics beyond average degree, such as clustering coefficients, motif frequencies, or subgraph counts, to better capture the qualitative differences between generated explanations.
  \item Apply the framework to larger and more diverse datasets where the expressiveness gap between 1-WL and higher-order tests is more pronounced.
\end{itemize}

% ============================================================
% 7. Conclusion
% ============================================================
\section{Conclusion}
\label{sec:conclusion}

We compared a standard 1-GNN with a hierarchical 1-2-GNN for model-level explanation generation using the GIN-Graph framework, with all configurations fully trained for 300 epochs across both datasets and both classes.

On MUTAG, both models achieve identical classification accuracy (89.5\%), yet the 1-2-GNN produces substantially better explanations (92\% validity, 0.80 validation score vs.\ 82\% validity, 0.71 validation score). This controlled comparison---where classification performance is held constant---provides evidence that higher-order message passing improves the structural quality of model-level explanations independently of classification accuracy. The 1-2-GNN's pairwise representations guide the generator toward more structurally realistic graphs with better degree distributions and higher embedding fidelity.

On PROTEINS, the 1-GNN dominates in both classification (77.6\% vs.\ 68.6\%) and explanation quality (0.98 vs.\ 0.83 validation score), with the 1-2-GNN's predictions collapsing to near-constant outputs. This confirms a fundamental principle: \emph{explanation quality is bounded by classifier quality}. The benefits of higher-order message passing for interpretability are dataset-dependent and require that the classifier successfully leverages its additional expressiveness.

Our fully differentiable dense wrapper enables GIN-Graph explanation generation for hierarchical $k$-GNN architectures while maintaining gradient flow through both node features and adjacency matrices. Additionally, our corrected validation metric---computing actual cosine similarity between generated and real graph embeddings rather than using prediction probability as a proxy---provides a more faithful measure of explanation quality. These technical contributions open the door to studying interpretability across the $k$-WL expressiveness hierarchy.

% ============================================================
% References
% ============================================================
\bibliographystyle{plain}
\begin{thebibliography}{7}

\bibitem[Borgwardt et~al.(2005)]{borgwardt2005protein}
K.~M. Borgwardt, C.~S. Ong, S.~Sch\"{o}nauer, S.~V.~N. Vishwanathan, A.~J. Smola, and H.-P. Kriegel.
\newblock Protein function prediction via graph kernels.
\newblock \emph{Bioinformatics}, 21(suppl\_1):i47--i56, 2005.

\bibitem[Cai et~al.(1992)]{cai1992optimal}
J.-Y. Cai, M.~F\"{u}rer, and N.~Immerman.
\newblock An optimal lower bound on the number of variables for graph identification.
\newblock \emph{Combinatorica}, 12(4):389--410, 1992.

\bibitem[Debnath et~al.(1991)]{debnath1991structure}
A.~K. Debnath, R.~L. {Lopez de Compadre}, G.~Debnath, A.~J. Shusterman, and C.~Hansch.
\newblock Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds.
\newblock \emph{J.\ Med.\ Chem.}, 34(2):786--797, 1991.

\bibitem[Gulrajani et~al.(2017)]{gulrajani2017improved}
I.~Gulrajani, F.~Ahmed, M.~Arjovsky, V.~Dumoulin, and A.~Courville.
\newblock Improved training of {W}asserstein {GAN}s.
\newblock In \emph{NeurIPS}, 2017.

\bibitem[Jang et~al.(2017)]{jang2017categorical}
E.~Jang, S.~Gu, and B.~Poole.
\newblock Categorical reparameterization with {G}umbel-softmax.
\newblock In \emph{ICLR}, 2017.

\bibitem[Morris et~al.(2019)]{morris2019weisfeiler}
C.~Morris, M.~Ritzert, M.~Fey, W.~L. Hamilton, J.~E. Lenssen, G.~Rattan, and M.~Grohe.
\newblock Weisfeiler and {L}eman go neural: Higher-order graph neural networks.
\newblock In \emph{AAAI}, 2019.

\bibitem[Sun et~al.(2025)]{sun2025gingraph}
J.~Sun, S.~Pei, F.~Zhang, and N.~V. Chawla.
\newblock {GIN-Graph}: A generative interpretation network for model-level explanation of graph neural networks.
\newblock \emph{Neurocomputing}, 2025.

\end{thebibliography}

\end{document}
