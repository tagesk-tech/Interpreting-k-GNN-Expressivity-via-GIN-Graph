\contentsline {section}{\numberline {1}Problem Setting}{3}{section.1}%
\contentsline {section}{\numberline {2}Stage 1: $k$-GNN Classification}{3}{section.2}%
\contentsline {subsection}{\numberline {2.1}The Weisfeiler--Leman Hierarchy}{3}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}1-GNN (Standard Message Passing)}{3}{subsection.2.2}%
\contentsline {paragraph}{Concrete dimensions.}{4}{section*.2}%
\contentsline {paragraph}{Matrix form (dense).}{4}{section*.3}%
\contentsline {paragraph}{Batched form.}{4}{section*.4}%
\contentsline {paragraph}{Graph-level readout.}{4}{section*.5}%
\contentsline {subsection}{\numberline {2.3}2-GNN (Pair Message Passing)}{4}{subsection.2.3}%
\contentsline {paragraph}{Initial features.}{4}{section*.6}%
\contentsline {paragraph}{Message passing.}{4}{section*.7}%
\contentsline {paragraph}{Concrete dimensions.}{5}{section*.8}%
\contentsline {paragraph}{Neighbourhood enumeration.}{5}{section*.9}%
\contentsline {paragraph}{Dense formulation.}{5}{section*.10}%
\contentsline {paragraph}{Graph-level readout.}{5}{section*.11}%
\contentsline {subsection}{\numberline {2.4}3-GNN (Triplet Message Passing)}{5}{subsection.2.4}%
\contentsline {paragraph}{Initial features.}{6}{section*.12}%
\contentsline {paragraph}{Soft iso-type (for generator gradient flow).}{6}{section*.13}%
\contentsline {paragraph}{Concrete dimensions.}{6}{section*.14}%
\contentsline {paragraph}{Neighbourhood enumeration.}{6}{section*.15}%
\contentsline {paragraph}{Message passing.}{6}{section*.16}%
\contentsline {paragraph}{Scalability.}{6}{section*.17}%
\contentsline {subsection}{\numberline {2.5}Hierarchical Models}{7}{subsection.2.5}%
\contentsline {paragraph}{1-2-GNN (\texttt {Hierarchical12GNN}).}{7}{section*.18}%
\contentsline {paragraph}{1-2-3-GNN (\texttt {Hierarchical123GNN}).}{7}{section*.19}%
\contentsline {paragraph}{Classifier MLP.}{7}{section*.20}%
\contentsline {subsection}{\numberline {2.6}$k$-GNN Training Procedure}{7}{subsection.2.6}%
\contentsline {paragraph}{Loss function.}{7}{section*.21}%
\contentsline {paragraph}{Optimizer.}{8}{section*.22}%
\contentsline {paragraph}{Training protocol.}{8}{section*.23}%
\contentsline {paragraph}{Parameter counts.}{8}{section*.24}%
\contentsline {section}{\numberline {3}Stage 2: GIN-Graph Explanation Generator}{8}{section.3}%
\contentsline {subsection}{\numberline {3.1}Architecture Overview}{8}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Generator Architecture}{8}{subsection.3.2}%
\contentsline {subsubsection}{\numberline {3.2.1}Backbone MLP}{8}{subsubsection.3.2.1}%
\contentsline {subsubsection}{\numberline {3.2.2}Adjacency Head}{9}{subsubsection.3.2.2}%
\contentsline {subsubsection}{\numberline {3.2.3}Gumbel-Softmax Reparameterisation}{9}{subsubsection.3.2.3}%
\contentsline {paragraph}{The Gumbel-Max trick.}{9}{section*.25}%
\contentsline {paragraph}{Gumbel-Softmax relaxation (Jang et al., 2017; Maddison et al., 2017).}{9}{section*.26}%
\contentsline {paragraph}{Straight-through estimator (\texttt {hard=True}).}{9}{section*.27}%
\contentsline {paragraph}{Application to edge sampling.}{10}{section*.28}%
\contentsline {paragraph}{Temperature during training vs.\ evaluation.}{10}{section*.29}%
\contentsline {subsubsection}{\numberline {3.2.4}Post-Gumbel Symmetrisation (Critical)}{10}{subsubsection.3.2.4}%
\contentsline {subsubsection}{\numberline {3.2.5}Node Feature Head}{10}{subsubsection.3.2.5}%
\contentsline {subsubsection}{\numberline {3.2.6}Generator Parameter Summary}{11}{subsubsection.3.2.6}%
\contentsline {subsection}{\numberline {3.3}Discriminator Architecture}{11}{subsection.3.3}%
\contentsline {subsubsection}{\numberline {3.3.1}Dense GCN Layers}{11}{subsubsection.3.3.1}%
\contentsline {paragraph}{Implementation detail.}{11}{section*.30}%
\contentsline {paragraph}{Concrete dimensions.}{11}{section*.31}%
\contentsline {subsubsection}{\numberline {3.3.2}Graph-Level Output}{11}{subsubsection.3.3.2}%
\contentsline {subsection}{\numberline {3.4}WGAN-GP Training}{12}{subsection.3.4}%
\contentsline {subsubsection}{\numberline {3.4.1}Discriminator Loss}{12}{subsubsection.3.4.1}%
\contentsline {subsubsection}{\numberline {3.4.2}Gradient Penalty}{12}{subsubsection.3.4.2}%
\contentsline {subsubsection}{\numberline {3.4.3}Real Data Preparation}{12}{subsubsection.3.4.3}%
\contentsline {subsubsection}{\numberline {3.4.4}Discriminator Training Step}{12}{subsubsection.3.4.4}%
\contentsline {subsection}{\numberline {3.5}Dense Forward Pass Through Pretrained $k$-GNN}{13}{subsection.3.5}%
\contentsline {subsubsection}{\numberline {3.5.1}1-GNN Wrapper (Fully Differentiable)}{13}{subsubsection.3.5.1}%
\contentsline {subsubsection}{\numberline {3.5.2}2-GNN Wrapper (Fully Differentiable)}{13}{subsubsection.3.5.2}%
\contentsline {paragraph}{Step 1: Build canonical pair features.}{13}{section*.32}%
\contentsline {paragraph}{Step 2: Apply pretrained 2-GNN layers.}{13}{section*.33}%
\contentsline {paragraph}{Step 3: Pool upper triangle.}{13}{section*.34}%
\contentsline {subsubsection}{\numberline {3.5.3}3-GNN Wrapper (Partial Gradient Flow)}{14}{subsubsection.3.5.3}%
\contentsline {subsection}{\numberline {3.6}Training Objective}{14}{subsection.3.6}%
\contentsline {subsubsection}{\numberline {3.6.1}Generator Loss}{14}{subsubsection.3.6.1}%
\contentsline {paragraph}{GAN loss.}{14}{section*.35}%
\contentsline {paragraph}{GNN guidance loss.}{14}{section*.36}%
\contentsline {paragraph}{Degree regularisation loss.}{14}{section*.37}%
\contentsline {subsubsection}{\numberline {3.6.2}Dynamic Weighting Schedule}{15}{subsubsection.3.6.2}%
\contentsline {paragraph}{Schedule function.}{15}{section*.38}%
\contentsline {paragraph}{Normalised progress.}{15}{section*.39}%
\contentsline {paragraph}{Derivative of $\lambda _t$.}{16}{section*.40}%
\contentsline {paragraph}{Intuition.}{16}{section*.41}%
\contentsline {subsubsection}{\numberline {3.6.3}Generator Training Step}{16}{subsubsection.3.6.3}%
\contentsline {subsubsection}{\numberline {3.6.4}Optimiser Details}{16}{subsubsection.3.6.4}%
\contentsline {section}{\numberline {4}Stage 3: Evaluation}{16}{section.4}%
\contentsline {subsection}{\numberline {4.1}Evaluation Protocol}{16}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Per-Graph Metrics}{17}{subsection.4.2}%
\contentsline {paragraph}{Edge thresholding.}{17}{section*.42}%
\contentsline {paragraph}{Active nodes and edges.}{17}{section*.43}%
\contentsline {paragraph}{Prediction probability.}{17}{section*.44}%
\contentsline {paragraph}{Embedding similarity.}{17}{section*.45}%
\contentsline {paragraph}{Degree score.}{17}{section*.46}%
\contentsline {paragraph}{Validation score.}{17}{section*.47}%
\contentsline {paragraph}{Validity.}{18}{section*.48}%
\contentsline {paragraph}{Granularity.}{18}{section*.49}%
\contentsline {section}{\numberline {5}Gradient Flow Analysis}{18}{section.5}%
\contentsline {subsection}{\numberline {5.1}Full Gradient Decomposition}{18}{subsection.5.1}%
\contentsline {paragraph}{Through $\tilde {\mathbf {A}}$.}{18}{section*.50}%
\contentsline {paragraph}{Through $\tilde {\mathbf {X}}$.}{18}{section*.51}%
\contentsline {subsection}{\numberline {5.2}Through Gumbel-Softmax}{18}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}Gradient Flow Summary by Model}{19}{subsection.5.3}%
\contentsline {section}{\numberline {6}Putting It All Together}{19}{section.6}%
\contentsline {section}{\numberline {7}Observed Results and Interpretation}{20}{section.7}%
\contentsline {subsection}{\numberline {7.1}Summary Table}{20}{subsection.7.1}%
\contentsline {subsection}{\numberline {7.2}Key Observations}{20}{subsection.7.2}%
\contentsline {paragraph}{1. Class asymmetry in MUTAG.}{20}{section*.52}%
\contentsline {paragraph}{2. Higher-order $\neq $ better explanations.}{20}{section*.53}%
\contentsline {paragraph}{3. PROTEINS is more amenable.}{20}{section*.54}%
\contentsline {section}{\numberline {8}Open Questions and Directions}{20}{section.8}%
\contentsline {section}{\numberline {9}Notation Reference}{21}{section.9}%
